{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjhwQFxseIrUGkxPBFmslK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GunroarCannon/E-Commerce-sql-streamlit-data-analysis/blob/main/E-Commerce-filesystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q4y1NCLpsUr",
        "outputId": "bf068468-20c1-46f4-fc1c-382a19ddae4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.43)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (0.3.8)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.49.1)\n",
            "Requirement already satisfied: streamlit-authenticator in /usr/local/lib/python3.12/dist-packages (0.4.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: bcrypt>=3.1.7 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (4.3.0)\n",
            "Requirement already satisfied: captcha>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (0.7.1)\n",
            "Requirement already satisfied: cryptography>=42.0.5 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (43.0.3)\n",
            "Requirement already satisfied: extra-streamlit-components>=0.1.70 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (0.1.81)\n",
            "Requirement already satisfied: PyJWT>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (2.10.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=42.0.5->streamlit-authenticator) (2.0.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=42.0.5->streamlit-authenticator) (2.23)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "âœ… All packages installed successfully!\n",
            "ðŸ“Š Ready to build your e-commerce data warehouse!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages in Google Colab\n",
        "!pip install pandas numpy sqlalchemy matplotlib dill pyngrok seaborn plotly\n",
        "!pip install streamlit streamlit-authenticator\n",
        "!pip install scikit-learn xgboost\n",
        "!pip install requests beautifulsoup4\n",
        "\n",
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine, inspect, MetaData, Table, Column, Integer, String, Float, DateTime, ForeignKey, Text\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker, relationship\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import requests\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"âœ… All packages installed successfully!\")\n",
        "print(\"ðŸ“Š Ready to build your e-commerce data warehouse!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataloader.py\n",
        "# Data Acquisition - Multiple E-commerce Dataset Options\n",
        "import requests\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "from io import StringIO\n",
        "\n",
        "class EcommerceDataAcquisition:\n",
        "    def __init__(self):\n",
        "        self.datasets = {}\n",
        "\n",
        "    def download_sample_ecommerce_data(self):\n",
        "        \"\"\"\n",
        "        Download sample e-commerce datasets from various sources\n",
        "        \"\"\"\n",
        "        print(\"ðŸ“¥ Downloading E-commerce datasets...\")\n",
        "\n",
        "        # Option 1: UK E-commerce data (Online Retail dataset)\n",
        "        # Yes, it exists. Should not fail\n",
        "        try:\n",
        "            url1 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\"\n",
        "\n",
        "            #too fictional and short\n",
        "            #    \"https://raw.githubusercontent.com/paulsamuel-w-e/E-commerce-Customer-Behaviour-Dataset/refs/heads/main/E-commerce.csv\"\n",
        "            #no price\n",
        "            #    https://raw.githubusercontent.com/gilangnr/e-commerce_public_dataset/refs/heads/main/all_data.csv\"\n",
        "            #too limited\n",
        "            #    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\"\n",
        "            print(\"Downloading Online Retail dataset...\")\n",
        "            uk_data = pd.read_excel(url1, engine='openpyxl')\n",
        "            self.datasets['retail'] = uk_data\n",
        "            print(f\"âœ… Retail data: {uk_data.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Retail download failed: {e}\")\n",
        "\n",
        "        # Option 2: Create synthetic comprehensive e-commerce data\n",
        "        # not needed\n",
        "        # self.create_synthetic_ecommerce_data()\n",
        "\n",
        "        return self.datasets\n",
        "\n",
        "    def create_synthetic_ecommerce_data(self):\n",
        "        \"\"\"\n",
        "        Create realistic synthetic e-commerce data for the warehouse\n",
        "\n",
        "\n",
        "        Just incase. It's a cool function.\n",
        "        \"\"\"\n",
        "        print(\"ðŸ­ Generating synthetic e-commerce data...\")\n",
        "\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Generate customers data\n",
        "        num_customers = 5000\n",
        "        customers = pd.DataFrame({\n",
        "            'customer_id': range(1, num_customers + 1),\n",
        "            'first_name': np.random.choice(['John', 'Jane', 'Mike', 'Sarah', 'David', 'Lisa', 'Chris', 'Emma'], num_customers),\n",
        "            'last_name': np.random.choice(['Smith', 'Johnson', 'Brown', 'Davis', 'Wilson', 'Moore', 'Taylor', 'Anderson'], num_customers),\n",
        "            'email': [f'user{i}@email.com' for i in range(1, num_customers + 1)],\n",
        "            'registration_date': pd.date_range('2020-01-01', '2024-01-01', periods=num_customers),\n",
        "            'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia'], num_customers),\n",
        "            'state': np.random.choice(['NY', 'CA', 'IL', 'TX', 'AZ', 'PA'], num_customers),\n",
        "            'country': 'USA',\n",
        "            'customer_segment': np.random.choice(['Premium', 'Standard', 'Basic'], num_customers, p=[0.2, 0.5, 0.3])\n",
        "        })\n",
        "\n",
        "        # Generate products data\n",
        "        num_products = 1000\n",
        "        categories = ['Electronics', 'Clothing', 'Home & Garden', 'Books', 'Sports', 'Beauty', 'Toys']\n",
        "        products = pd.DataFrame({\n",
        "            'product_id': range(1, num_products + 1),\n",
        "            'product_name': [f'Product {i}' for i in range(1, num_products + 1)],\n",
        "            'category': np.random.choice(categories, num_products),\n",
        "            'supplier_id': np.random.randint(1, 101, num_products),\n",
        "            'unit_price': np.round(np.random.exponential(50) + 10, 2),\n",
        "            'cost_price': lambda x: x * 0.7,  # Will be calculated\n",
        "            'launch_date': pd.date_range('2020-01-01', '2023-12-31', periods=num_products),\n",
        "            'brand': np.random.choice(['Brand A', 'Brand B', 'Brand C', 'Brand D', 'Brand E'], num_products)\n",
        "        })\n",
        "        products['cost_price'] = np.round(products['unit_price'] * 0.7, 2)\n",
        "\n",
        "        # Generate suppliers data\n",
        "        num_suppliers = 100\n",
        "        suppliers = pd.DataFrame({\n",
        "            'supplier_id': range(1, num_suppliers + 1),\n",
        "            'supplier_name': [f'Supplier {i}' for i in range(1, num_suppliers + 1)],\n",
        "            'contact_email': [f'supplier{i}@company.com' for i in range(1, num_suppliers + 1)],\n",
        "            'country': np.random.choice(['USA', 'China', 'Germany', 'Japan', 'India'], num_suppliers),\n",
        "            'rating': np.round(np.random.uniform(3.0, 5.0, num_suppliers), 1)\n",
        "        })\n",
        "\n",
        "        # Generate sales transactions\n",
        "        num_transactions = 50000\n",
        "        transactions = pd.DataFrame({\n",
        "            'transaction_id': range(1, num_transactions + 1),\n",
        "            'customer_id': np.random.randint(1, num_customers + 1, num_transactions),\n",
        "            'product_id': np.random.randint(1, num_products + 1, num_transactions),\n",
        "            'order_date': pd.date_range('2022-01-01', '2024-09-01', periods=num_transactions),\n",
        "            'quantity': np.random.randint(1, 6, num_transactions),\n",
        "            'channel': np.random.choice(['Website', 'Mobile App', 'Store', 'Social Media'], num_transactions, p=[0.4, 0.3, 0.2, 0.1]),\n",
        "            'payment_method': np.random.choice(['Credit Card', 'PayPal', 'Debit Card', 'Bank Transfer'], num_transactions),\n",
        "            'shipping_cost': np.round(np.random.uniform(0, 15, num_transactions), 2),\n",
        "            'discount_applied': np.random.choice([0, 5, 10, 15, 20], num_transactions, p=[0.5, 0.2, 0.15, 0.1, 0.05])\n",
        "        })\n",
        "\n",
        "        # Calculate revenue\n",
        "        product_prices = dict(zip(products['product_id'], products['unit_price']))\n",
        "        transactions['unit_price'] = transactions['product_id'].map(product_prices)\n",
        "        transactions['gross_revenue'] = transactions['quantity'] * transactions['unit_price']\n",
        "        transactions['discount_amount'] = transactions['gross_revenue'] * transactions['discount_applied'] / 100\n",
        "        transactions['net_revenue'] = transactions['gross_revenue'] - transactions['discount_amount']\n",
        "\n",
        "        # Generate marketing campaigns\n",
        "        campaigns = pd.DataFrame({\n",
        "            'campaign_id': range(1, 51),\n",
        "            'campaign_name': [f'Campaign {i}' for i in range(1, 51)],\n",
        "            'start_date': pd.date_range('2022-01-01', '2024-06-01', periods=50),\n",
        "            'end_date': pd.date_range('2022-02-01', '2024-07-01', periods=50),\n",
        "            'budget': np.round(np.random.uniform(1000, 50000, 50), 2),\n",
        "            'channel': np.random.choice(['Google Ads', 'Facebook', 'Email', 'Instagram', 'YouTube'], 50),\n",
        "            'target_segment': np.random.choice(['Premium', 'Standard', 'Basic', 'All'], 50)\n",
        "        })\n",
        "\n",
        "        # Store all datasets\n",
        "        self.datasets.update({\n",
        "            'customers': customers,\n",
        "            'products': products,\n",
        "            'suppliers': suppliers,\n",
        "            'transactions': transactions,\n",
        "            'campaigns': campaigns\n",
        "        })\n",
        "\n",
        "        print(\"âœ… Synthetic data generated successfully!\")\n",
        "        for name, df in self.datasets.items():\n",
        "            print(f\"   ðŸ“Š {name}: {df.shape}\")\n",
        "\n",
        "        return self.datasets\n",
        "\n",
        "    def save_datasets_to_csv(self, folder_path=\"data\"):\n",
        "        \"\"\"Save all datasets to CSV files\"\"\"\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        for name, df in self.datasets.items():\n",
        "            file_path = f\"{folder_path}/{name}.csv\"\n",
        "            df.to_csv(file_path, index=False)\n",
        "            print(f\"ðŸ’¾ Saved {name} to {file_path}\")\n",
        "\n",
        "# Initialize and run data acquisition\n",
        "data_acquisition = EcommerceDataAcquisition()\n",
        "datasets = data_acquisition.download_sample_ecommerce_data()\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nðŸ“‹ Sample data preview:\")\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n--- {name.upper()} ---\")\n",
        "    print(df.head(3))\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "\n",
        "main_dataset = datasets[\"retail\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knZRg24Mp2zz",
        "outputId": "e8931586-5103-4089-922a-4cb69503e779"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataloader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile schema.py\n",
        "\n",
        "from dataloader import *\n",
        "\n",
        "# Database Schema Design - Dimensional Modeling for E-commerce Data Warehouse\n",
        "'''\n",
        "Uses sqlalchemy to create_engine for dimensional models.\n",
        "Base class gotten from ext.declarative is the base for model definitions.\n",
        "'''\n",
        "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, DateTime, Date, Boolean, ForeignKey, Text\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker, relationship\n",
        "import sqlite3\n",
        "\n",
        "Base = declarative_base()\n",
        "from sqlalchemy import create_engine, Column, Integer, String, Float, Date, ForeignKey, Boolean\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "\n",
        "Base = declarative_base()\n",
        "\n",
        "class EcommerceDimensionalModel:\n",
        "    \"\"\"\n",
        "    Comprehensive dimensional model for e-commerce data warehouse\n",
        "    Following Kimball methodology with fact and dimension tables.\n",
        "\n",
        "    Where dimensions are descriptive and facts are statistics/numeric verbs.\n",
        "    \"\"\"\n",
        "    def __init__(self, db_path=\"ecommerce_warehouse.db\"):\n",
        "        self.db_path = db_path\n",
        "        self.engine = create_engine(f\"sqlite:///{db_path}\")\n",
        "\n",
        "        Base.metadata.drop_all(self.engine)\n",
        "        Base.metadata.create_all(self.engine)\n",
        "    # DIMENSION TABLES\n",
        "    class DimCustomer(Base):\n",
        "        __tablename__ = 'dim_customer'\n",
        "        customer_key = Column(Integer, primary_key=True, autoincrement=True)\n",
        "        customer_id = Column(Integer, unique=True, nullable=False)\n",
        "        country = Column(String(100))\n",
        "\n",
        "    class DimProduct(Base):\n",
        "        __tablename__ = 'dim_product'\n",
        "        product_key = Column(Integer, primary_key=True, autoincrement=True)\n",
        "        stock_code = Column(String(50), unique=True, nullable=False)\n",
        "        description = Column(String(255))\n",
        "\n",
        "    class DimDate(Base):\n",
        "        __tablename__ = 'dim_date'\n",
        "        date_key = Column(Integer, primary_key=True)  # YYYYMMDD format\n",
        "        full_date = Column(Date, unique=True, nullable=False)\n",
        "        year = Column(Integer)\n",
        "        month = Column(Integer)\n",
        "        day = Column(Integer)\n",
        "        week = Column(Integer)\n",
        "        weekday = Column(String(20))\n",
        "        is_weekend = Column(Boolean)\n",
        "\n",
        "    # FACT TABLE\n",
        "    class FactSales(Base):\n",
        "        __tablename__ = 'fact_sales'\n",
        "        sales_key = Column(Integer, primary_key=True, autoincrement=True)\n",
        "        invoice_no = Column(String(50))\n",
        "        date_key = Column(Integer, ForeignKey('dim_date.date_key'), nullable=False)\n",
        "        customer_key = Column(Integer, ForeignKey('dim_customer.customer_key'))\n",
        "        product_key = Column(Integer, ForeignKey('dim_product.product_key'))\n",
        "        quantity = Column(Integer)\n",
        "        unit_price = Column(Float)\n",
        "        revenue = Column(Float)  # Quantity * UnitPrice\n",
        "\n",
        "    def create_all_tables(self):\n",
        "        Base.metadata.create_all(self.engine)\n",
        "        print(\"âœ… Tables created successfully!\")\n",
        "\n",
        "\n",
        "    def get_table_info(self):\n",
        "        \"\"\"Get information about all tables\"\"\"\n",
        "        inspector = inspect(create_engine(f'sqlite:///{self.db_path}'))\n",
        "\n",
        "        print(\"ðŸ“‹ Database Tables:\")\n",
        "        for table in inspector.get_table_names():\n",
        "            print(f\"   ðŸ“Š {table}\")\n",
        "\n",
        "        return inspector\n",
        "\n",
        "# Create the dimensional model\n",
        "print(\"ðŸ­ Initializing E-commerce Dimensional Model...\")\n",
        "warehouse = EcommerceDimensionalModel()\n",
        "warehouse.create_all_tables()\n",
        "warehouse.get_table_info()\n",
        "\n",
        "print(\"\"\"\n",
        "ðŸŽ¯ Dimensional Model Summary:\n",
        "\n",
        "DIMENSION TABLES:\n",
        "â€¢ dim_customer - Customer information (CustomerID, Country)\n",
        "â€¢ dim_product - Product catalog (StockCode, Description)\n",
        "â€¢ dim_date - Date dimension (Year, Month, Day, Week, Weekday)\n",
        "\n",
        "FACT TABLES:\n",
        "â€¢ fact_sales - Transaction-level sales data (InvoiceNo, Quantity, UnitPrice, Revenue)\n",
        "\n",
        "ðŸ”‘ Key Features:\n",
        "âœ“ Star schema design with surrogate keys\n",
        "âœ“ Date dimension for time-series analysis\n",
        "âœ“ Supports sales & revenue analytics\n",
        "âœ“ Ready for customer, product & time-based queries\n",
        "âœ“ Marketing attribution modeling\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSxdP3Gwv_3t",
        "outputId": "3a709a4e-5abd-4066-eec6-cb531f04294a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting schema.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "\n",
        "from dataloader import *\n",
        "from schema import *\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy import text\n",
        "import logging\n",
        "import time\n",
        "\n",
        "class EcommerceETL:\n",
        "    def __init__(self, model_class):\n",
        "        self.model_class = model_class\n",
        "        self.engine = model_class.engine\n",
        "        self.Session = sessionmaker(bind=self.engine)\n",
        "\n",
        "        logging.basicConfig(level=logging.INFO, force=True)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def extract_raw_data(self, datasets):\n",
        "        \"\"\"Extract raw data from given sources\"\"\"\n",
        "        self.raw_data = datasets\n",
        "        print(\"yes\")\n",
        "        self.logger.info(f\"âœ… Extracted datasets: {list(datasets.keys())}\")\n",
        "        return datasets\n",
        "\n",
        "    def transform_and_load_dimensions(self):\n",
        "        \"\"\"Transform and load dimensions into DB\"\"\"\n",
        "        session = self.Session()\n",
        "        try:\n",
        "            self._load_dim_date(session)\n",
        "            self._load_dim_customer(session)\n",
        "            self._load_dim_product(session)\n",
        "            session.commit()\n",
        "\n",
        "            self._load_fact_sales(session)\n",
        "\n",
        "\n",
        "            session.commit()\n",
        "            self.logger.info(\"âœ… Dimensions loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            session.rollback()\n",
        "            self.logger.error(f\"âŒ ETL Error: {e}\")\n",
        "        finally:\n",
        "            session.close()\n",
        "\n",
        "\n",
        "    def _load_fact_sales_old(self, session):\n",
        "        self.logger.info(\"ðŸ’° Loading fact_sales...\")\n",
        "        fact_sales = []\n",
        "         # Prepare mappings from raw IDs to surrogate keys\n",
        "        customer_map = pd.read_sql(\"SELECT customer_key, customer_id FROM dim_customer\", self.model_class.engine)\n",
        "        product_map = pd.read_sql(\"SELECT product_key, stock_code FROM dim_product\", self.model_class.engine)\n",
        "\n",
        "        #dicts for faster look up\n",
        "\n",
        "        customer_dict = dict(zip(customer_map[\"customer_id\"], customer_map[\"customer_key\"]))\n",
        "        product_dict = dict(zip(product_map[\"stock_code\"], product_map[\"product_key\"]))\n",
        "\n",
        "\n",
        "        '''\n",
        "        TODO: Makes it faster\n",
        "transactions_df['InvoiceDate'] = pd.to_datetime(transactions_df['InvoiceDate'])\n",
        "transactions_df['date_key'] = transactions_df['InvoiceDate'].dt.strftime('%Y%m%d').astype(int)\n",
        "\n",
        "# Map surrogate keys using vectorized pandas map\n",
        "transactions_df['customer_key'] = transactions_df['CustomerID'].map(customer_dict)\n",
        "transactions_df['product_key'] = transactions_df['StockCode'].map(product_dict)\n",
        "\n",
        "# Calculate revenue\n",
        "transactions_df['revenue'] = transactions_df['Quantity'] * transactions_df['UnitPrice']\n",
        "\n",
        "        '''\n",
        "        for i, row in self.raw_data[\"transactions\"].iterrows():\n",
        "          fact_sales.append({\n",
        "              \"sales_key\": i,\n",
        "              \"invoice_no\": row[\"InvoiceNo\"],\n",
        "              \"date_key\": int(pd.to_datetime(row[\"InvoiceDate\"]).strftime('%Y%m%d')),\n",
        "              \"customer_key\": customer_dict.get(row[\"CustomerID\"]),\n",
        "              \"product_key\": product_dict.get(row[\"StockCode\"]),\n",
        "              \"quantity\": row[\"Quantity\"],\n",
        "              \"unit_price\": row[\"UnitPrice\"],\n",
        "              \"revenue\": row[\"Quantity\"]*row[\"UnitPrice\"]\n",
        "          })\n",
        "\n",
        "        session.bulk_insert_mappings(self.model_class.FactSales, fact_sales)\n",
        "        self.logger.info(f\"âœ… {len(fact_sales)} fact records loaded\")\n",
        "    def _load_fact_sales(self, session): #   def _load_fact_sales(self, session):\n",
        "        self.logger.info(\"ðŸ’° Loading fact_sales (vectorized)...\")\n",
        "\n",
        "        # Prepare mappings from raw IDs to surrogate keys\n",
        "        customer_map = pd.read_sql(\n",
        "            \"SELECT customer_key, customer_id FROM dim_customer\",\n",
        "            self.model_class.engine\n",
        "        )\n",
        "        product_map = pd.read_sql(\n",
        "            \"SELECT product_key, stock_code FROM dim_product\",\n",
        "            self.model_class.engine\n",
        "        )\n",
        "        self.logger.info(product_map.head(3))\n",
        "\n",
        "        transactions = self.raw_data[\"transactions\"].copy()\n",
        "        # 1. Normalize transactions columns\n",
        "        transactions['StockCode'] = transactions['StockCode'].astype(str).str.strip().str.upper()\n",
        "        transactions['CustomerID'] = transactions['CustomerID'].astype(pd.Int64Dtype())  # nullable integer\n",
        "\n",
        "        # 2. Normalize dimension maps\n",
        "        product_map['stock_code'] = product_map['stock_code'].astype(str).str.strip().str.upper()\n",
        "        customer_map['customer_id'] = customer_map['customer_id'].astype(int)\n",
        "\n",
        "        # 3. Build mapping dicts\n",
        "        product_dict = dict(zip(product_map['stock_code'], product_map['product_key']))\n",
        "        customer_dict = dict(zip(customer_map['customer_id'], customer_map['customer_key']))\n",
        "\n",
        "        # 4. Map keys\n",
        "        transactions['product_key'] = transactions['StockCode'].map(product_dict)\n",
        "        transactions['customer_key'] = transactions['CustomerID'].map(customer_dict)\n",
        "\n",
        "        count = 0\n",
        "        print(transactions['StockCode'].head(3))\n",
        "        print(product_map.head(3))\n",
        "        for i in transactions['StockCode']:\n",
        "            if i not in product_dict.keys():\n",
        "                print(\"Missing STOCK CODE\",i)\n",
        "                count += 1\n",
        "                if count > 10:\n",
        "                  break\n",
        "\n",
        "        # 5. Check missing keys\n",
        "        missing_products = transactions[transactions['product_key'].isna()]['StockCode'].unique()\n",
        "        missing_customers = transactions[transactions['customer_key'].isna()]['CustomerID'].unique()\n",
        "\n",
        "        print(\"Missing product keys:\", missing_products)\n",
        "        print(\"Missing customer keys:\", missing_customers)\n",
        "\n",
        "        #transactions['product_key'] = transactions['StockCode'].str.strip().str.upper().map(product_dict)\n",
        "        transactions['date_key'] = pd.to_datetime(transactions['InvoiceDate']).dt.strftime('%Y%m%d').astype(int)\n",
        "        transactions['revenue'] = transactions['Quantity'] * transactions['UnitPrice']\n",
        "\n",
        "        # Add a sales_key column (optional, can just use index)\n",
        "        transactions['sales_key'] = transactions.index\n",
        "\n",
        "        # Assign dummy keys for missing\n",
        "        dummy_customer_key = 0\n",
        "        dummy_product_key = 0\n",
        "\n",
        "        transactions['customer_key'] = transactions['customer_key'].fillna(dummy_customer_key)\n",
        "        transactions['product_key'] = transactions['product_key'].fillna(dummy_product_key)\n",
        "\n",
        "        transactions = transactions.dropna(subset=['customer_key', 'product_key'])\n",
        "        invalid_stockcodes = set(transactions['StockCode']) - set(product_dict.keys())\n",
        "        print(\"StockCodes not in dim_product:\", list(invalid_stockcodes)[:20])\n",
        "\n",
        "\n",
        "        # Keep only the columns needed for the fact table\n",
        "        fact_sales = transactions[['sales_key', 'InvoiceNo', 'date_key', 'customer_key',\n",
        "                                   'product_key', 'Quantity', 'UnitPrice', 'revenue']].rename(\n",
        "            columns={'Quantity': 'quantity', 'UnitPrice': 'unit_price'}\n",
        "        ).to_dict(orient='records')\n",
        "\n",
        "        # Bulk insert\n",
        "        session.bulk_insert_mappings(self.model_class.FactSales, fact_sales)\n",
        "        self.logger.info(f\"âœ… {len(fact_sales)} fact records loaded (vectorized)\")\n",
        "\n",
        "    def _load_dim_date(self, session):\n",
        "        self.logger.info(\"ðŸ“… Loading date dimension...\")\n",
        "        start_date = datetime(2010, 1, 1)\n",
        "        end_date = datetime(2012, 12, 31)\n",
        "\n",
        "        records = []\n",
        "        current_date = start_date\n",
        "        while current_date <= end_date:\n",
        "            records.append({\n",
        "                \"date_key\": int(current_date.strftime('%Y%m%d')),\n",
        "                \"full_date\": current_date.date(),\n",
        "                \"year\": current_date.year,\n",
        "                \"month\": current_date.month,\n",
        "                \"day\": current_date.day,\n",
        "                \"week\": current_date.isocalendar()[1],\n",
        "                \"weekday\": current_date.strftime('%A'),\n",
        "                \"is_weekend\": current_date.weekday() >= 5\n",
        "            })\n",
        "            current_date += timedelta(days=1)\n",
        "\n",
        "        session.bulk_insert_mappings(self.model_class.DimDate, records)\n",
        "        self.logger.info(f\"âœ… {len(records)} date records loaded\")\n",
        "\n",
        "    def _load_dim_customer(self, session):\n",
        "        self.logger.info(\"ðŸ‘¥ Loading customer dimension...\")\n",
        "        customers = self.raw_data[\"customers\"]\n",
        "        records = []\n",
        "        for i, row in customers.iterrows():\n",
        "            records.append({\n",
        "                \"customer_id\": row[\"CustomerID\"],\n",
        "                \"country\": row.get(\"Country\", \"Unknown\")\n",
        "            })\n",
        "        session.bulk_insert_mappings(self.model_class.DimCustomer, records)\n",
        "        self.logger.info(f\"âœ… {len(records)} customer records loaded\")\n",
        "    def _load_dim_product(self, session):\n",
        "        self.logger.info(\"ðŸ“¦ Loading product dimension...\")\n",
        "\n",
        "        # Original products table\n",
        "        products = self.raw_data[\"products\"].copy()\n",
        "        products['StockCode'] = products['StockCode'].astype(str).str.strip().str.upper()\n",
        "        products['Description'] = products['Description'].fillna(\"No description\")\n",
        "\n",
        "        # Drop exact duplicates (StockCode + Description)\n",
        "        products = products.drop_duplicates(subset=['StockCode'])\n",
        "\n",
        "        # Collect all StockCodes from transactions\n",
        "        transactions = self.raw_data.get(\"transactions\")\n",
        "        if transactions is not None:\n",
        "            transactions_codes = transactions['StockCode'].astype(str).str.strip().str.upper().unique()\n",
        "            missing_codes = set(transactions_codes) - set(products['StockCode'])\n",
        "            self.logger.info(\"Checking missing cause transaction is not null\")\n",
        "            self.logger.info(f\"Total transaction StockCodes: {len(transactions_codes)}\")\n",
        "            self.logger.info(f\"Total product StockCodes: {len(products['StockCode'])}\")\n",
        "            self.logger.info(f\"Missing codes count: {len(missing_codes)}\")\n",
        "\n",
        "            if missing_codes:\n",
        "                self.logger.info(f\"Adding {len(missing_codes)} missing StockCodes to dim_product...\")\n",
        "                missing_df = pd.DataFrame({\n",
        "                    'StockCode': list(missing_codes),\n",
        "                    'Description': 'Unknown Product'\n",
        "                })\n",
        "                products = pd.concat([products, missing_df], ignore_index=True)\n",
        "\n",
        "        # Prepare records for bulk insert\n",
        "        records = []\n",
        "        for i, row in products.iterrows():\n",
        "            records.append({\n",
        "                \"stock_code\": row[\"StockCode\"],\n",
        "                \"description\": row.get(\"Description\", \"No description\")\n",
        "            })\n",
        "\n",
        "        # Bulk insert into dim_product\n",
        "        session.bulk_insert_mappings(self.model_class.DimProduct, records)\n",
        "        self.logger.info(f\"âœ… {len(records)} product records loaded\")\n",
        "        time.sleep(1)\n",
        "\n",
        "    def run_query(self, sql):\n",
        "        \"\"\"\n",
        "        Run a raw SQL query on the warehouse and return a Pandas DataFrame.\n",
        "        \"\"\"\n",
        "        with self.engine.connect() as conn:\n",
        "            result = conn.execute(text(sql))\n",
        "            # Convert results to DataFrame\n",
        "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
        "        return df\n",
        "\n",
        "Base.metadata.drop_all(warehouse.engine)  # Drops old tables\n",
        "Base.metadata.create_all(warehouse.engine)\n",
        "\n",
        "# ðŸ”¹ Create dimensions from raw data (cleaned) ðŸ”¹\n",
        "\n",
        "# Customers: drop duplicates and missing IDs\n",
        "customers_df = main_dataset[['CustomerID', 'Country']].dropna(subset=['CustomerID']).drop_duplicates(subset=['CustomerID'])\n",
        "customers_df['CustomerID'] = customers_df['CustomerID'].astype(int)\n",
        "\n",
        "# Products: drop duplicates, drop missing StockCode, normalize StockCode, fill missing description\n",
        "products_df = main_dataset[['StockCode', 'Description']].copy()\n",
        "\n",
        "# Drop rows where StockCode is missing or empty after stripping\n",
        "products_df['StockCode'] = products_df['StockCode'].astype(str).str.strip().str.upper()\n",
        "products_df = products_df[products_df['StockCode'] != '']\n",
        "products_df = products_df.drop_duplicates(subset=['StockCode'])\n",
        "\n",
        "# Fill missing descriptions\n",
        "products_df['Description'] = products_df['Description'].fillna(\"No description\")\n",
        "\n",
        "# Suppliers: dummy table if none exists\n",
        "suppliers_df = pd.DataFrame({\"SupplierID\": [1], \"Name\": [\"Default Supplier\"]})\n",
        "\n",
        "# Transactions: drop duplicates, drop rows with missing critical info, normalize StockCode\n",
        "transactions_df = main_dataset[['InvoiceNo', 'CustomerID', 'UnitPrice', 'Quantity', 'StockCode', 'InvoiceDate']].dropna()\n",
        "transactions_df = transactions_df.drop_duplicates()\n",
        "\n",
        "transactions_df['StockCode'] = transactions_df['StockCode'].astype(str).str.strip().str.upper()\n",
        "\n",
        "transactions_df['customer_key'] = transactions_df['CustomerID'].map(customer_dict)\n",
        "transactions_df['product_key'] = transactions_df['StockCode'].map(product_dict)\n",
        "\n",
        "# Keep only rows with valid keys\n",
        "transactions_df = transactions_df.dropna(subset=['customer_key', 'product_key'])\n",
        "\n",
        "\n",
        "# Pass to ETL\n",
        "datasets = {\n",
        "    \"customers\": customers_df,\n",
        "    \"products\": products_df,\n",
        "    \"suppliers\": suppliers_df,\n",
        "    \"transactions\": transactions_df\n",
        "}\n",
        "\n",
        "etl = EcommerceETL(warehouse)\n",
        "etl.extract_raw_data(datasets)\n",
        "etl.transform_and_load_dimensions()\n",
        "\n",
        "class SQLQueries:\n",
        "    def __init__(self, etl):\n",
        "        self.etl = etl\n",
        "\n",
        "    # Top N customers by revenue\n",
        "    def top_n_customers(self, n=10):\n",
        "        padf = self.etl.run_query(f\"\"\"\n",
        "            SELECT c.customer_id, SUM(f.revenue) AS revenue\n",
        "            FROM fact_sales f\n",
        "            JOIN dim_customer c ON f.customer_key = c.customer_key\n",
        "            GROUP BY c.customer_id\n",
        "            ORDER BY revenue DESC\n",
        "            LIMIT {n}\n",
        "        \"\"\")\n",
        "        return padf\n",
        "\n",
        "    # Top sales by country\n",
        "    def top_sales_by_country(self):\n",
        "        padf = self.etl.run_query(f\"\"\"\n",
        "            SELECT c.country, SUM(f.revenue) AS revenue\n",
        "            FROM fact_sales f\n",
        "            JOIN dim_customer c ON f.customer_key = c.customer_key\n",
        "            GROUP BY c.country\n",
        "            ORDER BY revenue DESC\n",
        "        \"\"\")\n",
        "        return padf\n",
        "\n",
        "    # Top N products by revenue\n",
        "    def top_n_products(self, n=10):\n",
        "        padf =  self.etl.run_query(f\"\"\"\n",
        "            SELECT p.description, SUM(f.revenue) AS revenue\n",
        "            FROM fact_sales f\n",
        "            JOIN dim_product p ON f.product_key = p.product_key\n",
        "            GROUP BY p.description\n",
        "            ORDER BY revenue DESC\n",
        "            LIMIT {n}\n",
        "        \"\"\")\n",
        "        return padf\n",
        "\n",
        "    # Monthly sales trend\n",
        "    def monthly_sales_trend(self):\n",
        "        padf = self.etl.run_query(f\"\"\"\n",
        "            SELECT substr(f.date_key,1,6) AS year_month, SUM(f.revenue) AS revenue\n",
        "            FROM fact_sales f\n",
        "            GROUP BY year_month\n",
        "            ORDER BY year_month\n",
        "        \"\"\")\n",
        "        return padf\n",
        "\n",
        "    # RFM-style customer summary\n",
        "    def customer_rfm_summary(self):\n",
        "        padf = self.etl.run_query(f\"\"\"\n",
        "            SELECT\n",
        "                f.customer_key,\n",
        "                MAX(f.date_key) AS last_purchase,\n",
        "                COUNT(DISTINCT f.invoice_no) AS frequency,\n",
        "                SUM(f.revenue) AS monetary\n",
        "            FROM fact_sales f\n",
        "            GROUP BY f.customer_key\n",
        "        \"\"\")\n",
        "        return padf\n",
        "\n",
        "\n",
        "queries = SQLQueries(etl)\n",
        "customer_map = pd.read_sql(\n",
        "    \"SELECT customer_key, customer_id FROM dim_customer\",\n",
        "    etl.model_class.engine\n",
        ")\n",
        "product_map = pd.read_sql(\n",
        "    \"SELECT product_key, stock_code FROM dim_product\",\n",
        "    etl.model_class.engine\n",
        ")\n",
        "\n",
        "# dicts for faster lookup\n",
        "customer_dict = dict(zip(customer_map[\"customer_id\"], customer_map[\"customer_key\"]))\n",
        "product_dict = dict(zip(product_map[\"stock_code\"], product_map[\"product_key\"]))\n",
        "\n",
        "print(customer_dict)\n",
        "print(product_dict)\n",
        "\n",
        "\n",
        "\n",
        "# Top 10 customers\n",
        "top_customers = queries.top_n_customers(10)\n",
        "print(top_customers)\n",
        "\n",
        "# Top sales by country\n",
        "country_sales = queries.top_sales_by_country()\n",
        "print(country_sales)\n",
        "\n",
        "# Top 10 products\n",
        "top_products = queries.top_n_products(10)\n",
        "print(top_products)\n",
        "\n",
        "# Monthly sales trend\n",
        "monthly_trend = queries.monthly_sales_trend()\n",
        "print(monthly_trend)\n",
        "\n",
        "# Customer RFM summary\n",
        "rfm_summary = queries.customer_rfm_summary()\n",
        "print(rfm_summary.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcRlxc_1wQ_R",
        "outputId": "b2cf7249-21f4-4c5e-b71e-985d333b2731"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile app.py\n",
        "\n",
        "from dataloader import *\n",
        "from schema import *\n",
        "from model import *\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import sqlite3\n",
        "from datetime import datetime, timedelta\n",
        "import hashlib\n",
        "import hmac\n",
        "from sqlalchemy import create_engine\n",
        "import numpy as np\n",
        "import dill\n",
        "\n",
        "# Page Configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"ðŸ›ï¸ E-commerce Analytics Dashboard\",\n",
        "    page_icon=\"ðŸ“Š\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for advanced styling\n",
        "def load_css():\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
        "\n",
        "    /* Root variables for theming */\n",
        "    :root {\n",
        "        --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        --secondary-gradient: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
        "        --success-gradient: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
        "        --warning-gradient: linear-gradient(135deg, #fa709a 0%, #fee140 100%);\n",
        "        --dark-bg: #0e1117;\n",
        "        --card-bg: rgba(255, 255, 255, 0.05);\n",
        "        --glass-bg: rgba(255, 255, 255, 0.1);\n",
        "        --text-primary: #ffffff;\n",
        "        --text-secondary: rgba(255, 255, 255, 0.7);\n",
        "        --border-color: rgba(255, 255, 255, 0.1);\n",
        "    }\n",
        "\n",
        "    /* Global Styles */\n",
        "    .main .block-container {\n",
        "        padding-top: 2rem;\n",
        "        max-width: 100%;\n",
        "    }\n",
        "\n",
        "    body {\n",
        "        font-family: 'Inter', sans-serif;\n",
        "        background: var(--dark-bg);\n",
        "        color: var(--text-primary);\n",
        "    }\n",
        "\n",
        "    /* Grid background animation */\n",
        "    .stApp::before {\n",
        "        content: '';\n",
        "        position: fixed;\n",
        "        top: 0;\n",
        "        left: 0;\n",
        "        width: 100%;\n",
        "        height: 100%;\n",
        "        background:\n",
        "            linear-gradient(90deg, rgba(255,255,255,0.02) 1px, transparent 1px),\n",
        "            linear-gradient(rgba(255,255,255,0.02) 1px, transparent 1px);\n",
        "        background-size: 50px 50px;\n",
        "        animation: gridMove 20s linear infinite;\n",
        "        pointer-events: none;\n",
        "        z-index: -1;\n",
        "    }\n",
        "\n",
        "    @keyframes gridMove {\n",
        "        0% { transform: translate(0, 0); }\n",
        "        100% { transform: translate(50px, 50px); }\n",
        "    }\n",
        "\n",
        "    /* Header styling */\n",
        "    .main-header {\n",
        "        background: var(--primary-gradient);\n",
        "        padding: 2rem 3rem;\n",
        "        border-radius: 20px;\n",
        "        margin-bottom: 2rem;\n",
        "        box-shadow: 0 20px 40px rgba(102, 126, 234, 0.3);\n",
        "        backdrop-filter: blur(20px);\n",
        "        border: 1px solid rgba(255, 255, 255, 0.1);\n",
        "    }\n",
        "\n",
        "    .main-header h1 {\n",
        "        color: white;\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: 700;\n",
        "        margin-bottom: 0.5rem;\n",
        "        text-shadow: 0 2px 10px rgba(0,0,0,0.3);\n",
        "    }\n",
        "\n",
        "    .main-header p {\n",
        "        color: rgba(255, 255, 255, 0.9);\n",
        "        font-size: 1.1rem;\n",
        "        font-weight: 400;\n",
        "        margin: 0;\n",
        "    }\n",
        "\n",
        "    /* Metric cards */\n",
        "    .metric-card {\n",
        "        background: var(--glass-bg);\n",
        "        backdrop-filter: blur(20px);\n",
        "        border: 1px solid var(--border-color);\n",
        "        border-radius: 16px;\n",
        "        padding: 1.5rem;\n",
        "        margin: 0.5rem 0;\n",
        "        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);\n",
        "        transition: all 0.3s ease;\n",
        "        position: relative;\n",
        "        overflow: hidden;\n",
        "    }\n",
        "\n",
        "    .metric-card::before {\n",
        "        content: '';\n",
        "        position: absolute;\n",
        "        top: 0;\n",
        "        left: 0;\n",
        "        right: 0;\n",
        "        height: 3px;\n",
        "        background: var(--primary-gradient);\n",
        "    }\n",
        "\n",
        "    .metric-card:hover {\n",
        "        transform: translateY(-5px);\n",
        "        box-shadow: 0 15px 45px rgba(0, 0, 0, 0.4);\n",
        "        border-color: rgba(255, 255, 255, 0.2);\n",
        "    }\n",
        "\n",
        "    .metric-value {\n",
        "        font-size: 2.2rem;\n",
        "        font-weight: 700;\n",
        "        color: var(--text-primary);\n",
        "        margin-bottom: 0.5rem;\n",
        "    }\n",
        "\n",
        "    .metric-label {\n",
        "        font-size: 0.9rem;\n",
        "        color: var(--text-secondary);\n",
        "        font-weight: 500;\n",
        "        text-transform: uppercase;\n",
        "        letter-spacing: 0.5px;\n",
        "    }\n",
        "\n",
        "    .metric-change {\n",
        "        font-size: 0.8rem;\n",
        "        font-weight: 600;\n",
        "        padding: 0.2rem 0.5rem;\n",
        "        border-radius: 12px;\n",
        "        margin-top: 0.5rem;\n",
        "        display: inline-block;\n",
        "    }\n",
        "\n",
        "    .metric-change.positive {\n",
        "        background: rgba(76, 175, 80, 0.2);\n",
        "        color: #4CAF50;\n",
        "        border: 1px solid rgba(76, 175, 80, 0.3);\n",
        "    }\n",
        "\n",
        "    .metric-change.negative {\n",
        "        background: rgba(244, 67, 54, 0.2);\n",
        "        color: #f44336;\n",
        "        border: 1px solid rgba(244, 67, 54, 0.3);\n",
        "    }\n",
        "\n",
        "    /* Sidebar styling */\n",
        "    .css-1d391kg {\n",
        "        background: var(--glass-bg);\n",
        "        backdrop-filter: blur(20px);\n",
        "        border-right: 1px solid var(--border-color);\n",
        "    }\n",
        "\n",
        "    /* Filter containers */\n",
        "    .filter-container {\n",
        "        background: var(--card-bg);\n",
        "        backdrop-filter: blur(10px);\n",
        "        border: 1px solid var(--border-color);\n",
        "        border-radius: 12px;\n",
        "        padding: 1rem;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "\n",
        "    /* Chart containers */\n",
        "    .chart-container {\n",
        "        background: var(--card-bg);\n",
        "        backdrop-filter: blur(10px);\n",
        "        border: 1px solid var(--border-color);\n",
        "        border-radius: 16px;\n",
        "        padding: 1.5rem;\n",
        "        margin: 1rem 0;\n",
        "        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "\n",
        "    /* Custom button styling */\n",
        "    .stButton > button {\n",
        "        background: var(--primary-gradient);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        border-radius: 12px;\n",
        "        padding: 0.5rem 1.5rem;\n",
        "        font-weight: 600;\n",
        "        transition: all 0.3s ease;\n",
        "        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);\n",
        "    }\n",
        "\n",
        "    .stButton > button:hover {\n",
        "        transform: translateY(-2px);\n",
        "        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);\n",
        "    }\n",
        "\n",
        "    /* Login form styling */\n",
        "    .login-form {\n",
        "        max-width: 400px;\n",
        "        margin: 0 auto;\n",
        "        padding: 2rem;\n",
        "        background: var(--glass-bg);\n",
        "        backdrop-filter: blur(20px);\n",
        "        border: 1px solid var(--border-color);\n",
        "        border-radius: 20px;\n",
        "        box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3);\n",
        "    }\n",
        "\n",
        "    .login-header {\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "\n",
        "    .login-header h2 {\n",
        "        background: var(--primary-gradient);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        background-clip: text;\n",
        "        font-size: 2rem;\n",
        "        font-weight: 700;\n",
        "        margin-bottom: 0.5rem;\n",
        "    }\n",
        "\n",
        "    /* Success/Error alerts */\n",
        "    .alert {\n",
        "        padding: 1rem;\n",
        "        border-radius: 12px;\n",
        "        margin: 1rem 0;\n",
        "        backdrop-filter: blur(10px);\n",
        "    }\n",
        "\n",
        "    .alert-success {\n",
        "        background: rgba(76, 175, 80, 0.1);\n",
        "        border: 1px solid rgba(76, 175, 80, 0.3);\n",
        "        color: #4CAF50;\n",
        "    }\n",
        "\n",
        "    .alert-error {\n",
        "        background: rgba(244, 67, 54, 0.1);\n",
        "        border: 1px solid rgba(244, 67, 54, 0.3);\n",
        "        color: #f44336;\n",
        "    }\n",
        "\n",
        "    /* Responsive design */\n",
        "    @media (max-width: 768px) {\n",
        "        .main-header {\n",
        "            padding: 1.5rem;\n",
        "        }\n",
        "\n",
        "        .main-header h1 {\n",
        "            font-size: 2rem;\n",
        "        }\n",
        "\n",
        "        .metric-value {\n",
        "            font-size: 1.8rem;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    /* Loading animation */\n",
        "    .loading-spinner {\n",
        "        width: 40px;\n",
        "        height: 40px;\n",
        "        border: 4px solid rgba(102, 126, 234, 0.3);\n",
        "        border-top: 4px solid #667eea;\n",
        "        border-radius: 50%;\n",
        "        animation: spin 1s linear infinite;\n",
        "        margin: 20px auto;\n",
        "    }\n",
        "\n",
        "    @keyframes spin {\n",
        "        0% { transform: rotate(0deg); }\n",
        "        100% { transform: rotate(360deg); }\n",
        "    }\n",
        "\n",
        "    /* Hide Streamlit branding */\n",
        "    #MainMenu {visibility: hidden;}\n",
        "    footer {visibility: hidden;}\n",
        "    header {visibility: hidden;}\n",
        "\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Authentication functions\n",
        "def hash_password(password):\n",
        "    \"\"\"Hash a password for storing.\"\"\"\n",
        "    return hashlib.sha256(str.encode(password)).hexdigest()\n",
        "\n",
        "def check_password(stored_password, provided_password):\n",
        "    \"\"\"Verify a stored password against provided password.\"\"\"\n",
        "    return stored_password == hash_password(provided_password)\n",
        "\n",
        "def init_auth():\n",
        "    \"\"\"Initialize authentication state.\"\"\"\n",
        "    if 'authenticated' not in st.session_state:\n",
        "        st.session_state.authenticated = False\n",
        "    if 'username' not in st.session_state:\n",
        "        st.session_state.username = \"\"\n",
        "\n",
        "# User database (in production, use a proper database)\n",
        "USERS = {\n",
        "    \"admin\": hash_password(\"admin123\"),\n",
        "    \"analyst\": hash_password(\"analyst123\"),\n",
        "    \"manager\": hash_password(\"manager123\"),\n",
        "    \"demo\": hash_password(\"demo123\")\n",
        "}\n",
        "\n",
        "def login_page():\n",
        "    \"\"\"Display login page.\"\"\"\n",
        "    st.markdown('<div class=\"login-form\">', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "        <div class=\"login-header\">\n",
        "            <h2>ðŸ›ï¸ E-commerce Analytics</h2>\n",
        "            <p style=\"color: rgba(255,255,255,0.7);\">Sign in to access your dashboard</p>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with st.form(\"login_form\"):\n",
        "        username = st.text_input(\"Username\", placeholder=\"Enter your username\")\n",
        "        password = st.text_input(\"Password\", type=\"password\", placeholder=\"Enter your password\")\n",
        "        submit_button = st.form_submit_button(\"ðŸ” Sign In\", use_container_width=True)\n",
        "\n",
        "        if submit_button:\n",
        "            if username in USERS and check_password(USERS[username], password):\n",
        "                st.session_state.authenticated = True\n",
        "                st.session_state.username = username\n",
        "                st.success(\"âœ… Login successful!\")\n",
        "                st.rerun()\n",
        "            else:\n",
        "                st.error(\"âŒ Invalid username or password\")\n",
        "\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    # Demo credentials\n",
        "    st.markdown(\"\"\"\n",
        "        <div style=\"margin-top: 2rem; padding: 1rem; background: rgba(255,255,255,0.05); border-radius: 12px;\">\n",
        "            <h4 style=\"margin-bottom: 1rem;\">ðŸ“ Demo Credentials:</h4>\n",
        "            <div style=\"font-family: monospace; font-size: 0.9rem;\">\n",
        "                <strong>Username:</strong> demo<br>\n",
        "                <strong>Password:</strong> demo123\n",
        "            </div>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize your database connection and classes here\n",
        "@st.cache_resource\n",
        "def init_database():\n",
        "    \"\"\"Initialize database connection and ETL classes.\"\"\"\n",
        "    # Replace with your actual database initialization\n",
        "    try:\n",
        "        # warehouse = EcommerceDimensionalModel()\n",
        "        # etl = EcommerceETL(warehouse)\n",
        "        queries = SQLQueries(etl)\n",
        "        # return warehouse, etl, queries\n",
        "\n",
        "        # For demo purposes, using dummy data\n",
        "        return warehouse, etl, queriesn\n",
        "    except Exception as e:\n",
        "        st.error(f\"Database initialization failed: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Sample data for demonstration (replace with your actual data)\n",
        "@st.cache_data\n",
        "def load_sample_data():\n",
        "    \"\"\"Load sample data for demonstration.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Sample sales data\n",
        "        dates = pd.date_range('2023-01-01', '2024-12-31', freq='D')\n",
        "        np.random.seed(42)\n",
        "\n",
        "        sales_data = pd.DataFrame({\n",
        "            'date': dates,\n",
        "            'revenue': np.random.normal(10000, 2000, len(dates)).clip(min=0),\n",
        "            'orders': np.random.poisson(50, len(dates)),\n",
        "            'customers': np.random.poisson(30, len(dates))\n",
        "        })\n",
        "\n",
        "        # Ensure date column is datetime\n",
        "        sales_data['date'] = pd.to_datetime(sales_data['date'])\n",
        "\n",
        "        # Sample country data\n",
        "        countries = ['United Kingdom', 'Germany', 'France', 'Netherlands', 'Belgium', 'Switzerland', 'Austria', 'Italy']\n",
        "        country_data = pd.DataFrame({\n",
        "            'country': countries,\n",
        "            'revenue': np.random.uniform(50000, 500000, len(countries)),\n",
        "            'customers': np.random.randint(100, 1000, len(countries))\n",
        "        })\n",
        "\n",
        "        # Sample product data\n",
        "        products = [f'Product {i}' for i in range(1, 21)]\n",
        "        product_data = pd.DataFrame({\n",
        "            'product': products,\n",
        "            'revenue': np.random.uniform(10000, 100000, len(products)),\n",
        "            'quantity': np.random.randint(100, 2000, len(products))\n",
        "        })\n",
        "\n",
        "        return sales_data, country_data, product_data\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading sample data: {e}\")\n",
        "        # Return empty dataframes as fallback\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "def create_metric_card(title, value, change=None, format_func=None):\n",
        "    \"\"\"Create a styled metric card.\"\"\"\n",
        "    if format_func:\n",
        "        formatted_value = format_func(value)\n",
        "    else:\n",
        "        formatted_value = f\"{value:,.0f}\" if isinstance(value, (int, float)) else str(value)\n",
        "\n",
        "    change_html = \"\"\n",
        "    if change is not None:\n",
        "        change_class = \"positive\" if change >= 0 else \"negative\"\n",
        "        change_symbol = \"â†—ï¸\" if change >= 0 else \"â†˜ï¸\"\n",
        "        change_html = f'<div class=\"metric-change {change_class}\">{change_symbol} {abs(change):.1f}%</div>'\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "        <div class=\"metric-card\">\n",
        "            <div class=\"metric-value\">{formatted_value}</div>\n",
        "            <div class=\"metric-label\">{title}</div>\n",
        "            {change_html}\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def create_charts(sales_data, country_data, product_data, date_range, selected_countries):\n",
        "    \"\"\"Create all dashboard charts.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Convert date_range to datetime for comparison\n",
        "        if len(date_range) == 2:\n",
        "            start_date = pd.to_datetime(date_range[0])\n",
        "            end_date = pd.to_datetime(date_range[1])\n",
        "            # Filter data based on selections\n",
        "            filtered_sales = sales_data[\n",
        "                (sales_data['date'] >= start_date) &\n",
        "                (sales_data['date'] <= end_date)\n",
        "            ]\n",
        "        else:\n",
        "            filtered_sales = sales_data\n",
        "\n",
        "        if filtered_sales.empty:\n",
        "            st.warning(\"No data available for the selected date range.\")\n",
        "            return None, None, None, None\n",
        "\n",
        "        filtered_countries = country_data[country_data['country'].isin(selected_countries)]\n",
        "\n",
        "        # 1. Sales Trend Chart\n",
        "        fig_trend = go.Figure()\n",
        "        fig_trend.add_trace(go.Scatter(\n",
        "            x=filtered_sales['date'],\n",
        "            y=filtered_sales['revenue'],\n",
        "            mode='lines',\n",
        "            name='Daily Revenue',\n",
        "            line=dict(color='#667eea', width=3),\n",
        "            fill='tonexty',\n",
        "            fillcolor='rgba(102, 126, 234, 0.1)'\n",
        "        ))\n",
        "\n",
        "        fig_trend.update_layout(\n",
        "            title=\"ðŸ“ˆ Sales Trend Over Time\",\n",
        "            xaxis_title=\"Date\",\n",
        "            yaxis_title=\"Revenue ($)\",\n",
        "            plot_bgcolor='rgba(0,0,0,0)',\n",
        "            paper_bgcolor='rgba(0,0,0,0)',\n",
        "            font=dict(color='white'),\n",
        "            title_font_size=16,\n",
        "            showlegend=False,\n",
        "            xaxis=dict(gridcolor='rgba(255,255,255,0.1)'),\n",
        "            yaxis=dict(gridcolor='rgba(255,255,255,0.1)')\n",
        "        )\n",
        "\n",
        "        # 2. Revenue by Country\n",
        "        fig_country = px.bar(\n",
        "            filtered_countries.head(10),\n",
        "            x='country',\n",
        "            y='revenue',\n",
        "            title=\"ðŸŒ Revenue by Country (Top 10)\",\n",
        "            color='revenue',\n",
        "            color_continuous_scale='viridis'\n",
        "        )\n",
        "        fig_country.update_layout(\n",
        "            plot_bgcolor='rgba(0,0,0,0)',\n",
        "            paper_bgcolor='rgba(0,0,0,0)',\n",
        "            font=dict(color='white'),\n",
        "            title_font_size=16,\n",
        "            xaxis=dict(gridcolor='rgba(255,255,255,0.1)'),\n",
        "            yaxis=dict(gridcolor='rgba(255,255,255,0.1)')\n",
        "        )\n",
        "\n",
        "        # 3. Top Products\n",
        "        fig_products = px.pie(\n",
        "            product_data.head(8),\n",
        "            values='revenue',\n",
        "            names='product',\n",
        "            title=\"ðŸ† Top Products by Revenue\",\n",
        "            color_discrete_sequence=px.colors.qualitative.Set3\n",
        "        )\n",
        "        fig_products.update_layout(\n",
        "            plot_bgcolor='rgba(0,0,0,0)',\n",
        "            paper_bgcolor='rgba(0,0,0,0)',\n",
        "            font=dict(color='white'),\n",
        "            title_font_size=16,\n",
        "            showlegend=True,\n",
        "            legend=dict(\n",
        "                orientation=\"v\",\n",
        "                yanchor=\"middle\",\n",
        "                y=0.5,\n",
        "                xanchor=\"left\",\n",
        "                x=1.01\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 4. Monthly Revenue Heatmap\n",
        "        monthly_data = filtered_sales.copy()\n",
        "        monthly_data['month'] = monthly_data['date'].dt.month\n",
        "        monthly_data['year'] = monthly_data['date'].dt.year\n",
        "        monthly_pivot = monthly_data.groupby(['year', 'month'])['revenue'].sum().unstack(fill_value=0)\n",
        "\n",
        "        if not monthly_pivot.empty:\n",
        "            fig_heatmap = px.imshow(\n",
        "                monthly_pivot.values,\n",
        "                x=[f\"M{i}\" for i in range(1, 13)],\n",
        "                y=monthly_pivot.index,\n",
        "                title=\"ðŸ”¥ Revenue Heatmap (Monthly)\",\n",
        "                color_continuous_scale='viridis',\n",
        "                aspect='auto'\n",
        "            )\n",
        "            fig_heatmap.update_layout(\n",
        "                plot_bgcolor='rgba(0,0,0,0)',\n",
        "                paper_bgcolor='rgba(0,0,0,0)',\n",
        "                font=dict(color='white'),\n",
        "                title_font_size=16,\n",
        "                xaxis_title=\"Month\",\n",
        "                yaxis_title=\"Year\"\n",
        "            )\n",
        "        else:\n",
        "            # Create empty heatmap if no data\n",
        "            fig_heatmap = go.Figure()\n",
        "            fig_heatmap.update_layout(\n",
        "                title=\"ðŸ”¥ Revenue Heatmap (Monthly) - No Data\",\n",
        "                plot_bgcolor='rgba(0,0,0,0)',\n",
        "                paper_bgcolor='rgba(0,0,0,0)',\n",
        "                font=dict(color='white'),\n",
        "                title_font_size=16\n",
        "            )\n",
        "\n",
        "        return fig_trend, fig_country, fig_products, fig_heatmap\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error creating charts: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "def main_dashboard():\n",
        "    \"\"\"Main dashboard interface.\"\"\"\n",
        "\n",
        "    # Header\n",
        "    st.markdown(f\"\"\"\n",
        "        <div class=\"main-header\">\n",
        "            <h1>ðŸ›ï¸ E-commerce Analytics Dashboard</h1>\n",
        "            <p>Welcome back, <strong>{st.session_state.username}</strong> â€¢ Real-time insights into your business performance</p>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Initialize database (replace with your actual implementation)\n",
        "    warehouse, etl, queries = init_database()\n",
        "\n",
        "    # Load sample data for demo\n",
        "    sales_data, country_data, product_data = load_sample_data()\n",
        "\n",
        "    # Sidebar filters\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"### ðŸŽ›ï¸ Dashboard Filters\")\n",
        "\n",
        "        # Date range filter\n",
        "        st.markdown('<div class=\"filter-container\">', unsafe_allow_html=True)\n",
        "        st.subheader(\"ðŸ“… Date Range\")\n",
        "        date_range = st.date_input(\n",
        "            \"Select date range\",\n",
        "            value=(datetime(2024, 1, 1), datetime(2024, 12, 31)),\n",
        "            min_value=datetime(2023, 1, 1),\n",
        "            max_value=datetime(2024, 12, 31)\n",
        "        )\n",
        "\n",
        "        # Ensure date_range is always a tuple\n",
        "        if not isinstance(date_range, tuple):\n",
        "            if hasattr(date_range, '__iter__') and len(date_range) == 2:\n",
        "                date_range = tuple(date_range)\n",
        "            else:\n",
        "                date_range = (datetime(2024, 1, 1), datetime(2024, 12, 31))\n",
        "        elif len(date_range) == 1:\n",
        "            date_range = (date_range[0], date_range[0])\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        # Country filter\n",
        "        st.markdown('<div class=\"filter-container\">', unsafe_allow_html=True)\n",
        "        st.subheader(\"ðŸŒ Countries\")\n",
        "        available_countries = country_data['country'].tolist()\n",
        "        selected_countries = st.multiselect(\n",
        "            \"Select countries\",\n",
        "            available_countries,\n",
        "            default=available_countries[:5]\n",
        "        )\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        # Refresh button\n",
        "        if st.button(\"ðŸ”„ Refresh Data\", use_container_width=True):\n",
        "            st.cache_data.clear()\n",
        "            st.rerun()\n",
        "\n",
        "        # Logout button\n",
        "        if st.button(\"ðŸšª Logout\", use_container_width=True):\n",
        "            st.session_state.authenticated = False\n",
        "            st.session_state.username = \"\"\n",
        "            st.rerun()\n",
        "\n",
        "    # Key Metrics Row\n",
        "    st.markdown(\"### ðŸ“Š Key Performance Indicators\")\n",
        "\n",
        "    # Filter sales data for metrics\n",
        "    if len(date_range) == 2:\n",
        "        start_date = pd.to_datetime(date_range[0])\n",
        "        end_date = pd.to_datetime(date_range[1])\n",
        "        filtered_sales = sales_data[\n",
        "            (sales_data['date'] >= start_date) &\n",
        "            (sales_data['date'] <= end_date)\n",
        "        ]\n",
        "    else:\n",
        "        filtered_sales = sales_data\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        total_revenue = filtered_sales['revenue'].sum()\n",
        "        create_metric_card(\"Total Revenue\", total_revenue, change=12.5, format_func=lambda x: f\"${x:,.0f}\")\n",
        "\n",
        "    with col2:\n",
        "        total_orders = filtered_sales['orders'].sum()\n",
        "        create_metric_card(\"Total Orders\", total_orders, change=8.3)\n",
        "\n",
        "    with col3:\n",
        "        avg_order_value = total_revenue / total_orders if total_orders > 0 else 0\n",
        "        create_metric_card(\"Avg Order Value\", avg_order_value, change=-2.1, format_func=lambda x: f\"${x:.0f}\")\n",
        "\n",
        "    with col4:\n",
        "        total_customers = filtered_sales['customers'].sum()\n",
        "        create_metric_card(\"Total Customers\", total_customers, change=15.7)\n",
        "\n",
        "    # Charts Section\n",
        "    if selected_countries:\n",
        "        charts = create_charts(sales_data, country_data, product_data, date_range, selected_countries)\n",
        "\n",
        "        if all(chart is not None for chart in charts):\n",
        "            fig_trend, fig_country, fig_products, fig_heatmap = charts\n",
        "\n",
        "            # First row of charts\n",
        "            col1, col2 = st.columns([2, 1])\n",
        "\n",
        "            with col1:\n",
        "                st.markdown('<div class=\"chart-container\">', unsafe_allow_html=True)\n",
        "                st.plotly_chart(fig_trend, use_container_width=True)\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "            with col2:\n",
        "                st.markdown('<div class=\"chart-container\">', unsafe_allow_html=True)\n",
        "                st.plotly_chart(fig_products, use_container_width=True)\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "            # Second row of charts\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.markdown('<div class=\"chart-container\">', unsafe_allow_html=True)\n",
        "                st.plotly_chart(fig_country, use_container_width=True)\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "            with col2:\n",
        "                st.markdown('<div class=\"chart-container\">', unsafe_allow_html=True)\n",
        "                st.plotly_chart(fig_heatmap, use_container_width=True)\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.error(\"âŒ Unable to generate charts. Please check your data and try again.\")\n",
        "\n",
        "        # Data Tables Section\n",
        "        st.markdown(\"### ðŸ“‹ Detailed Analytics\")\n",
        "\n",
        "        tab1, tab2, tab3 = st.tabs([\"ðŸ† Top Products\", \"ðŸŒ Country Performance\", \"ðŸ“ˆ Sales Data\"])\n",
        "\n",
        "        with tab1:\n",
        "            st.markdown('<div class=\"chart-container\">', unsafe_allow_html=True)\n",
        "            st.dataframe(\n",
        "                product_data.head(10).style.format({\n",
        "                    'revenue': '${:,.0f}',\n",
        "                    'quantity': '{:,}'\n",
        "                }),\n",
        "                use_container_width=True\n",
        "            )\n",
        "            st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        with tab2:\n",
        "            st.markdown('<div class=\"chart-container\">', unsafe_allow_html=True)\n",
        "            filtered_country_display = country_data[country_data['country'].isin(selected_countries)]\n",
        "            st.dataframe(\n",
        "                filtered_country_display.style.format({\n",
        "                    'revenue': '${:,.0f}',\n",
        "                    'customers': '{:,}'\n",
        "                }),\n",
        "                use_container_width=True\n",
        "            )\n",
        "            st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        with tab3:\n",
        "            st.markdown('<div class=\"chart-container\">', unsafe_allow_html=True)\n",
        "            st.dataframe(\n",
        "                filtered_sales.tail(20).style.format({\n",
        "                    'revenue': '${:,.0f}',\n",
        "                    'orders': '{:,}',\n",
        "                    'customers': '{:,}'\n",
        "                }),\n",
        "                use_container_width=True\n",
        "            )\n",
        "            st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    else:\n",
        "        st.warning(\"âš ï¸ Please select at least one country to display charts.\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main application entry point.\"\"\"\n",
        "\n",
        "    # Load custom CSS\n",
        "    load_css()\n",
        "\n",
        "    # Initialize authentication\n",
        "    init_auth()\n",
        "\n",
        "    # Check authentication\n",
        "    if not st.session_state.authenticated:\n",
        "        login_page()\n",
        "    else:\n",
        "        main_dashboard()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyryAJxUwtPQ",
        "outputId": "46e82e83-33d8-41a4-8c30-1cc1a6723ecf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok\n",
        "!ngrok config add-authtoken 32TBaW0daeIghPAn9337TQk7zsT_4Py9Yw2LxAmSN9iXmrqBR\n",
        "\n",
        "# Start Streamlit on port 8501\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "ngrok.kill()  # Kill any old tunnels\n",
        "time.sleep(1)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Run the app in the background\n",
        "!streamlit run app.py --server.port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk39mQI_p56W",
        "outputId": "0d164e42-b8ff-48ae-d24f-2e151d2870bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Public URL: NgrokTunnel: \"https://15c7021ffbbf.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "ðŸ“¥ Downloading E-commerce datasets...\n",
            "Downloading Online Retail dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-19T16:36:06+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Retail data: (541909, 8)\n",
            "\n",
            "ðŸ“‹ Sample data preview:\n",
            "\n",
            "--- RETAIL ---\n",
            "  InvoiceNo StockCode  ... CustomerID         Country\n",
            "0    536365    85123A  ...    17850.0  United Kingdom\n",
            "1    536365     71053  ...    17850.0  United Kingdom\n",
            "2    536365    84406B  ...    17850.0  United Kingdom\n",
            "\n",
            "[3 rows x 8 columns]\n",
            "Shape: (541909, 8)\n",
            "ðŸ­ Initializing E-commerce Dimensional Model...\n",
            "âœ… Tables created successfully!\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/app.py\", line 3, in <module>\n",
            "    from schema import *\n",
            "  File \"/content/schema.py\", line 88, in <module>\n",
            "    warehouse.get_table_info()\n",
            "  File \"/content/schema.py\", line 76, in get_table_info\n",
            "    inspector = inspect(create_engine(f'sqlite:///{self.db_path}'))\n",
            "                ^^^^^^^\n",
            "NameError: name 'inspect' is not defined. Did you mean: 'inspector'? Or did you forget to import 'inspect'?\n"
          ]
        }
      ]
    }
  ]
}